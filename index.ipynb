{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my first to Machine learning \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Intro Group by\n",
    "# Splitting the data into groups based on some criteria\n",
    "# Applying a function to echa group independently\n",
    "# combining the results into a data structure\n",
    "\n",
    "# On a dataframe we obtain groupy object by calling groupby() function.\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"A\" : [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "    \"B\" : [\"One\", \"One\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "    \"C\" : np.random.random(8),\n",
    "    \"D\" : np.random.random(8)\n",
    "})\n",
    "# Grouping by a column label, selecting column labels and then applying the dataFrameGroupby.sum() function to see the resulting groups\n",
    "df.groupby(\"A\")[[\"C\", \"D\"]].sum()\n",
    "\n",
    "# Grouping by multiple columns labels forms multiindex\n",
    "df.groupby([\"A\", \"B\"]).sum()\n",
    "\n",
    "\n",
    "grouped = df.groupby(\"A\") # or  df.groupby(df['A])\n",
    "grouped = df.groupby(\"B\")\n",
    "grouped = df.groupby(['A', 'B'])\n",
    "\n",
    "\n",
    "# A data set called drinks by country\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "drinks.head()\n",
    "# drinks.info()\n",
    "\n",
    "# print( \"The mean of beer serving\",  drinks.beer_servings.mean())\n",
    "\n",
    "# variations in all continent\n",
    "drinks.groupby('continent').beer_servings.mean()\n",
    "drinks[drinks.continent == 'Africa'].beer_servings.mean()\n",
    "drinks.groupby('continent').beer_servings.agg(['mean', 'max', 'min', 'count'])\n",
    "\n",
    "# drinks.groupby('continent').mean() you need to select columns with numerical values only and group them together\n",
    "\n",
    "# selecting columns with numeric data\n",
    "numeric_cols = drinks.select_dtypes(include='number').columns \n",
    "\n",
    "drinks.groupby('continent')[numeric_cols].mean()\n",
    "\n",
    "\n",
    "drinks[drinks.continent == 'Europe'].beer_servings.mean()\n",
    "\n",
    "\n",
    "# agg() allows us to categorise more functions at once\n",
    "drinks.groupby('continent').beer_servings.agg([\"count\", \"max\", 'min', 'mean'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting an object into groups\n",
    "speeds = pd.DataFrame(\n",
    "    [\n",
    "        (\"bird\", \"Falconiformes\", 389.0),\n",
    "        (\"bird\", \"Psittaciformes\", 24.0),\n",
    "        (\"mammal\", \"Carnivora\", 80.2),\n",
    "        (\"mammal\", \"Primates\", np.nan),\n",
    "        (\"mammal\", \"Carnivora\", 58),\n",
    "        \n",
    "    ],\n",
    "    index = ['falcom', 'parrot', 'lion', 'monkey', 'leopard'],\n",
    "    columns=(\"class\", \"order\", \"max_speed\")\n",
    ")\n",
    "speeds.head()\n",
    "speeds.groupby()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  how to calculate summary statistics\n",
    "titanic = pd.read_csv(\"Datasets/titanic.csv\")\n",
    "\n",
    "titanic.head()\n",
    "\n",
    "# Aggregating statistics - mean, min, max, count\n",
    "titanic['Age'].mean()\n",
    "\n",
    "# statistics are applied to columns with numerical data\n",
    "# Operations in general exclude missing data and operate across rows by default\n",
    "\n",
    "# what is the median age and fare\n",
    "titanic[[\"Age\", \"Fare\"]].median() # the selection of a two columns returns a dataframe\n",
    "\n",
    "titanic[['Age', 'Fare']].describe()\n",
    "\n",
    "# specific combinations of aggregating statistics for given columns can be defined using the DataFrame.agg() method:\n",
    "titanic.agg(\n",
    "    {\n",
    "        'Age' : ['min', 'max', 'median', 'skew'],\n",
    "        'Fare': ['min', 'max', 'median', 'mean']\n",
    "    }\n",
    ")\n",
    "\n",
    "# What is the average age for male vs female\n",
    "titanic[[\"Sex\", 'Age']].groupby(\"Sex\").mean() # a subselection is made for sex and age. and then groupby is applied on sex\n",
    "\n",
    "# if we dont explicitly select columns the mean method is applied to each column containing numerical columns by passing numeric_only = True\n",
    "titanic.groupby(\"Sex\").mean(numeric_only=True)\n",
    "\n",
    "''' \n",
    "If we are only interested in the average age for each gender the selection of columns (rectangular brackets[] as usual) \n",
    "is suported on the grouped data.\n",
    "'''\n",
    "titanic.groupby('Sex')[\"Age\"].mean()\n",
    "\n",
    "# What is the mean ticket fare price for each of the sex and cabin class combinations?\n",
    "titanic.groupby(['Sex', \"Pclass\"])[\"Fare\"].mean()\n",
    "\n",
    "# grouping can be done by multiple columns at the same time. Provide the column names as a list to the groupby() method.\n",
    "\n",
    "# counting the number of records by category\n",
    "# what is the number of passengers in each of the cabin classes?\n",
    "titanic['Pclass'].value_counts() # value counts method counts the number of records for each category\n",
    "\n",
    "# using groupby() function\n",
    "titanic.groupby('Pclass')['Pclass'].count()\n",
    "\n",
    "# Both size and count can be used in combination with groupby. Size includes NaN values and provides the size of the table, count excludes the missing values. \n",
    "\n",
    "\n",
    "# How to manipulate textual data\n",
    "titanic.head()\n",
    "# make all name charaters lowercase\n",
    "titanic['Name'].str.lower() # str is the accessor\n",
    "\n",
    "# create a new column Surname that contains the surname of the passengers by extracting the part before the comma\n",
    "titanic['Name'].str.split(',') # Each value is retrned s a list of two elements, the part before the comma and the aprt after the comma\n",
    "\n",
    "titanic['Surname'] = titanic['Name'].str.split(',').str.get(0) # we use te str accessor and apply Series.str.get() to extract the relevant part\n",
    "\n",
    "titanic['Surname'] \n",
    "\n",
    "\n",
    "# extract the passenger data about the countess on board of the Titanic\n",
    "titanic['Name'].str.contains('countess')\n",
    "\n",
    "titanic[titanic['Name'].str.contains('countess')]\n",
    "\n",
    "titanic.head(20)\n",
    "titanic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(subset=['Cabin'], inplace=True)\n",
    "titanic.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with missing values\n",
    "\n",
    "# pandas uses different sentinel values to represent a missing value depending on the datatype\n",
    "\n",
    "M = pd.Series([1, 2], dtype=np.int64).reindex([0, 1, 2])\n",
    "M\n",
    "df = pd.Series([True, False], dtype=np.bool_).reindex([0, 1, 2])\n",
    "df\n",
    "# Detecting these missing values use the isna() or notna() methods\n",
    "M.notna() # or isna() will also consider None a missing value\n",
    "\n",
    "None == None\n",
    "np.nan == np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data\n",
    "''' \n",
    "categoricals are pandas data types corresponding t categorical variables in statistics. categorical variables takes a limited and usually fixed number of possible values\n",
    "\n",
    "categorical data might have an order\n",
    "\n",
    "'''\n",
    "# Object creation\n",
    "s = pd.Series(['a', 'b', 'c', 'a'], dtype='category')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statisctics\n",
    "df1 = pd.DataFrame(\n",
    "    {\"A\": [1.0, np.nan, 3.0, 5.0, np.nan], \"B\": [np.nan, 2.0, 3.0, np.nan, 6.0]}\n",
    ")\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [5.0, 2.0, 4.0, np.nan, 3.0, 7.0],\n",
    "        \"B\": [np.nan, np.nan, 3.0, 4.0, 6.0, 8.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "df1\n",
    "df2\n",
    "df1[\"A\"].sum(0, skipna=False)\n",
    "\n",
    "# Missing data - by default is not included in the computations\n",
    "# df1.dropna(how='any') # dropna drops any values with missing data\n",
    "df1.fillna(value=5)\n",
    "\n",
    "df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197625 entries, 0 to 197624\n",
      "Data columns (total 11 columns):\n",
      " #   Column                                                                Non-Null Count   Dtype \n",
      "---  ------                                                                --------------   ----- \n",
      " 0   C/A                                                                   197625 non-null  object\n",
      " 1   UNIT                                                                  197625 non-null  object\n",
      " 2   SCP                                                                   197625 non-null  object\n",
      " 3   STATION                                                               197625 non-null  object\n",
      " 4   LINENAME                                                              197625 non-null  object\n",
      " 5   DIVISION                                                              197625 non-null  object\n",
      " 6   DATE                                                                  197625 non-null  object\n",
      " 7   TIME                                                                  197625 non-null  object\n",
      " 8   DESC                                                                  197625 non-null  object\n",
      " 9   ENTRIES                                                               197625 non-null  object\n",
      " 10  EXITS                                                                 197625 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 16.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DIVISION\n",
       "IRT    72198\n",
       "IND    69274\n",
       "BMT    41727\n",
       "PTH    12788\n",
       "SRT     1386\n",
       "RIT      252\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas data types\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "turn = pd.read_csv(\"Datasets/turnstile_180901.txt\", dtype=str)\n",
    "turn.sample(2)\n",
    "\n",
    "turn.info()\n",
    "\n",
    "# using map() to transform values\n",
    "\n",
    "# passing a dictionary\n",
    "# One of the most straightforward ways to use the .map() method on a pandas Series is with a dictionary of values\n",
    "# you want to use to replace other values.\n",
    "\n",
    "turn['DIVISION'].value_counts() # value_counts is used frequently to understand the distribution of categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2018</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0006736067</td>\n",
       "      <td>0002283184                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2018</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0006736087</td>\n",
       "      <td>0002283188                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2018</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0006736105</td>\n",
       "      <td>0002283229                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2018</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0006736180</td>\n",
       "      <td>0002283314                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/25/2018</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0006736349</td>\n",
       "      <td>0002283384                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197620</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/31/2018</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0000005554</td>\n",
       "      <td>0000000348                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197621</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/31/2018</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0000005554</td>\n",
       "      <td>0000000348                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197622</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/31/2018</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0000005554</td>\n",
       "      <td>0000000348                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197623</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/31/2018</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0000005554</td>\n",
       "      <td>0000000348                                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197624</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/31/2018</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>0000005554</td>\n",
       "      <td>0000000348                                    ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197625 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C/A  UNIT       SCP        STATION LINENAME DIVISION        DATE  \\\n",
       "0        A002  R051  02-00-00          59 ST  NQR456W      NaN  08/25/2018   \n",
       "1        A002  R051  02-00-00          59 ST  NQR456W      NaN  08/25/2018   \n",
       "2        A002  R051  02-00-00          59 ST  NQR456W      NaN  08/25/2018   \n",
       "3        A002  R051  02-00-00          59 ST  NQR456W      NaN  08/25/2018   \n",
       "4        A002  R051  02-00-00          59 ST  NQR456W      NaN  08/25/2018   \n",
       "...       ...   ...       ...            ...      ...      ...         ...   \n",
       "197620  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      NaN  08/31/2018   \n",
       "197621  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      NaN  08/31/2018   \n",
       "197622  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      NaN  08/31/2018   \n",
       "197623  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      NaN  08/31/2018   \n",
       "197624  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      NaN  08/31/2018   \n",
       "\n",
       "            TIME     DESC     ENTRIES  \\\n",
       "0       00:00:00  REGULAR  0006736067   \n",
       "1       04:00:00  REGULAR  0006736087   \n",
       "2       08:00:00  REGULAR  0006736105   \n",
       "3       12:00:00  REGULAR  0006736180   \n",
       "4       16:00:00  REGULAR  0006736349   \n",
       "...          ...      ...         ...   \n",
       "197620  05:00:00  REGULAR  0000005554   \n",
       "197621  09:00:00  REGULAR  0000005554   \n",
       "197622  13:00:00  REGULAR  0000005554   \n",
       "197623  17:00:00  REGULAR  0000005554   \n",
       "197624  21:00:00  REGULAR  0000005554   \n",
       "\n",
       "       EXITS                                                                 \n",
       "0       0002283184                                    ...                    \n",
       "1       0002283188                                    ...                    \n",
       "2       0002283229                                    ...                    \n",
       "3       0002283314                                    ...                    \n",
       "4       0002283384                                    ...                    \n",
       "...                                                   ...                    \n",
       "197620  0000000348                                    ...                    \n",
       "197621  0000000348                                    ...                    \n",
       "197622  0000000348                                    ...                    \n",
       "197623  0000000348                                    ...                    \n",
       "197624  0000000348                                    ...                    \n",
       "\n",
       "[197625 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division_mapping = {\n",
    "    \"IRT\": \"Interborough Rapid Transit Company\",\n",
    "    \"IND\": \"Independent Subway System\",\n",
    "    \"BMT\": \"Brooklyn–Manhattan Transit Corporation\",\n",
    "    \"PTH\": \"Port Authority Trans-Hudson (PATH)\",\n",
    "    \"SRT\": \"Staten Island Rapid Transit\",\n",
    "    \"RIT\": \"Roosevelt Island Tram\"\n",
    "}\n",
    "# we can call the .map() method to return a Series with the abbreviations transformed into full names\n",
    "turn['DIVISION'].map(division_mapping)\n",
    "\n",
    "\n",
    "# Lets go ahead and replace the Division column in turn with the new transformed values:\n",
    "turn['DIVISION'] = turn['DIVISION'].map(division_mapping)\n",
    "turn['DIVISION'].value_counts()\n",
    "\n",
    "# Passing in a function\n",
    "# another way to use the .map() method is by passing in a function\n",
    "\n",
    "# Let's look at the linenae column\n",
    "turn['LINENAME'].value_counts()\n",
    "\n",
    "def contains_n(text):\n",
    "    if \"N\" in text:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "\n",
    "turn['LINENAME'].map(contains_n)\n",
    "\n",
    "# or the shorter,  more pythoninc way\n",
    "# (this overwrites the previous function)\n",
    "\n",
    "def contains_n(text):\n",
    "    return \"N\" in text\n",
    "turn['LINENAME'].map(contains_n)\n",
    "\n",
    "# The .apply( method can be used )\n",
    "\n",
    "# info - provides us with information about the characteristics of the dataframe\n",
    "# describe() - EDA is to dig into the summary statistics of the dataset and get a feel for the data each column contains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
